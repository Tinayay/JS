%%% Preamble
\documentclass[paper=a4, fontsize=11pt]{scrartcl}	% Article class of KOMA-script with 11pt font and a4 format
\usepackage[T1]{fontenc}
\usepackage{fourier}

\usepackage[english]{babel}															% English language/hyphenation
\usepackage[protrusion=true,expansion=true]{microtype}				% Better typography
\usepackage{amsmath,amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}		
\usepackage{hyperref}
\usepackage{algorithm}

\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage{mathtools}								% Math packages
\usepackage[pdftex]{graphicx}														% Enable pdflatex
\usepackage{url}
\linespread{1.1} % Line spacing
\usepackage[margin = 2.5cm]{geometry}


%%% Custom sectioning (sectsty package)
\usepackage{sectsty}												% Custom sectioning (see below)
\allsectionsfont{\centering \normalfont\scshape}	% Change font of al section commands


%%% Custom headers/footers (fancyhdr package)
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhead{}														% No page header
\fancyfoot[L]{\small Team JS: Jonathan Irvin Gunawan and Khor Shi-Jie}		% You may remove/edit this line 
\fancyfoot[C]{}													% Empty
\fancyfoot[R]{\thepage}									% Pagenumbering
\renewcommand{\headrulewidth}{1pt}			% Remove header underlines
\renewcommand{\footrulewidth}{1pt}				% Remove footer underlines
\setlength{\headheight}{13.6pt}


%%% Equation and float numbering
\numberwithin{equation}{section}		% Equationnumbering: section.eq#
\numberwithin{figure}{section}			% Figurenumbering: section.fig#
\numberwithin{table}{section}				% Tablenumbering: section.tab#

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

%%% Maketitle metadata
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} 	% Horizontal rule

\title{
		%\vspace{-1in} 	
		\usefont{OT1}{bch}{b}{n}
		\normalfont \normalsize \textsc{CS5234 Combinatorial and Graph Algorithms} \\ [25pt]
		\horrule{0.5pt} \\[0.4cm]
		\huge Traveling Salesman Experiment \\
		\horrule{2pt} \\[0.5cm]
}
\author{
		\normalfont 								\normalsize
       Team JS: Jonathan Irvin Gunawan, Khor Shi-Jie\\[-3pt]		\normalsize
        \today
}
\date{}



%%% Begin document
\begin{document}
\maketitle

\section{Introduction}
The study of traveling salesman problem (TSP) is a natural generalization of the Hamiltonian cycle problem. We are interested to identify a cycle within a weighted graph such that the cycle includes all vertices in the graph and each vertex is only visited once in the cycle. In addition, we would to identify the Hamiltonian cycle with the minimum sum of edge weight. A close analogue to this problem is the Chinese postman problem which seeks to identify a tour of minimum weight that traverses each edge in the graph at least once. While the exact solution to the Chinese postman problem can be obtained in polynomial time, it is surprising that a subtle change in the requirement of the problem makes the Travelling Salesman Problem unsolvable in polynomial time. In particular, we note that

\begin{theorem}
TSP is NP-Hard.
\end{theorem}

\begin{proof}
We will reduce a directed Hamiltonian Cycle Problem into TSP. Given a directed graph $G$, we construct a weighted complete directed graph $G'$ which has the same vertices as $G$. In addition, we assign a weight of 1 to the edges in $G$ which were originally in $G'$, and a weight of $\infty$ otherwise. Suppose we found a solution to the TSP using graph $G'$ that has finite weight. Then, each of the edges must have weight 1 and hence must be present in the original graph $G$. As such, the solution to the TSP in $G'$ is also a solution to the Hamiltonian Cycle Problem in $G$. On the other hand, if the solution to TSP in $G'$ has infinite weight, then there is no Hamiltonian cycle which only consist of edge weight 1. Hence, there is no Hamiltonian cycle in $G$. As such, the directed Hamiltonian Cycle Problem reduces to TSP. Since the directed Hamiltonian Cycle problem is NP-Hard, TSP is also NP-Hard.
\end{proof}

There has been considerable research done in the past in determining the exact solution for TSP in a graph. A naive algorithm that checks all possible Hamiltonian cycle will incur $O(n!)$ time. It is possible to improve the runtime to $O(n^{2}2^n)$ using dynamic programming (i.e. Held-Karp algorithm), but even such algorithm will take significant time on graphs with small number of vertices\footnote{On a modern computer, it is possible to obtain the optimal solution using Held-Karp algorithm within 1 second for a graph with less than 18 nodes. \cite{steven} Any more vertices will incur a much higher runtime.}. Researchers have explored other approaches such as branch-and-bound algorithms and linear programming. Currently, the record for the highest number of vertices in a graph in which a TSP solution is found is approximately 85,900 nodes\footnote{Found by Applegate et al. using Concorde TSP Solver. \cite{appleman}}. Nevertheless, this is a small quantity compared to many real world instances of TSP.

Due to the impossibility of find a polynomial-time algorithm to solve TSP and the relevance of TSP to real life problems, there has been a lot of research that seeks to find an efficient approximation algorithm with a small approximation ratio. Within our course, we have explored several approximation algorithm to solve the TSP, including a 2-approximation algorithm\footnote{This algorithm only applies for a metric TSP. The same algorithm can be applied to obtain approximate solutions to M-R TSP and G-R TSP as these variants are equivalent.} based on constructing a minimum spanning tree (MST), and a 1.5-approximation algorithm that include the application of a minimum weight perfect matching algorithm. However, the effectiveness of these algorithms are only theoretical in nature. While the worst-case bounds for these algorithms are irrefutable, the optimality of these algorithm may differ from our expectations when we apply them to real world data (i.e. a 2-approximation algorithm may perform better on average than a 1.5-approximation algorithm). As such, this project aims to compare the suitability of various approximation algorithm when applied to graphs obtained from real world data or other random means. 

\section{Problem Formulation}

Generally, there are four variants of TSP that one can seek to solve. We can either have a graph in which the distance function is a metric, or a graph with a generic distance function. In addition, we can also choose to allow repeated vertices within our solution. The four variants are summarized in the table below:

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\multicolumn{1}{|l|}{} & Repeats & No Repeats \\ \hline
Metric                 & M-R TSP & M-NR TSP   \\ \hline
General                & G-R TSP & G-NR TSP   \\ \hline
\end{tabular}
\end{table}

We have shown in class that M-R TSP, M-NR TSP and G-R TSP are equivalent. For our project, we are more interested in M-NR TSP as we are using data obtained from the real world. In addition, we will assume that the graph is non-directional, and the distance between any two vertices is well-defined. 

For this project, we will implement four different approximation algorithms and profile the performances on a set of random graphs and real world data. The four approximation algorithms are:
\begin{enumerate}
\item \textit{Nearest neighbour heuristics.} We start from a cycle with only one vertex in the cycle. Then, while there are vertices which are not included within our cycle, we choose a vertex which is closest our cycle. Then, we add the vertex to the cycle at a position whereby the increase in the length of the cycle is minimal. Once all the vertices are added to the cycle, we will obtain a $O(log n)$-approximate solution to the TSP (to be proven in the next section).  
\item \textit{Minimum spanning tree.} We will build a minimum spanning tree for the graph and conduct a DFS traversal on the graph. Within the DFS traversal, we will skip any vertices which has already been visited. This will produce a 2-approximate solution to the TSP (proven in class).
\item \textit{1.5-approximate algorithm.} After finding the minimum spanning tree of the graph, instead of conducting a DFS, we add edges to the graph until all vertices in the graph have even degree. Then, we can find an Eulerian tour for the graph. The edges to be added will be selecting using a minimum weight perfect matching algorithm such as a modified Edmond's Blossom algorithm.\cite{kolmogorov}
\item \textit{2-opt algorithm.} This algorithm makes use of the fact that a cycle without crossing is shorter than a cycle with crossing under the assumption of triangle inequality. We will refine any random cycle until there can be no more improvement to the weights. This algorithm is an $O(\sqrt{n})$-approximate algorithm on average case. \cite{christian}
\end{enumerate}

We are interested in the optimality of the solution produced by the above four algorithms, as well as the runtime in producing the solutions. In particular, we want to know how well these algorithms will perform on random graphs and real world data. 

In our project, we will first implement methods to generate random graphs and prepare 5 such graphs for experimentation. Then, we will parse real world data from (to be confirmed) and (to be confirmed) and store them in a weighted graph. We will apply each approximation algorithm on our generated graphs and obtain the weight of TSP solution produced by each algorithm. Each algorithm will be executed thrice and the average runtime taken for the algorithms will be calculated. Upon collecting these data, we will compare the results and conclude on the effectiveness of each approximation algorithm.

\section{Algorithms and Theory}

In this section, we will describe the implementation of the four approximation algorithms proposed in the previous section. We will assume that the graph is stored as an adjacency list. 

\subsection{Nearest Neighbour Heuristic}
\begin{algorithm}
\caption{Nearest Neighbour Heursitics}\label{neighbour}
\begin{algorithmic}[1]
\Procedure{Nearest-Neighbour-Heuristics}{$g$}\Comment{Returns the TSP approximation}
   \State Set $visited[v]\gets$ false, for all $v\in V$
   \State $TSP\gets\emptyset$
   \State $u\gets 0$
   \State $visited[u]\gets$ true
   \While{there is unvisited vertex}
      \State $v\gets$ unvisited vertex that is closest to $u$
      \State $TSP\gets TSP\cup(u,v)$
      \State $visited[v]\gets$ true
      \State $u\gets v$
   \EndWhile\label{nearestneighbourwhile}
   \State \textbf{return} $TSP$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{theorem}
Algorithm 1 is $O(\log n)$ approximation
\end{theorem}

\begin{proof}
Suppose for every vertex $u\in V$, let $l_{u}$ be the length of the edge leaving vertex $u$ to vertex $v$, which is the nearest unvisited vertex from $u$.
\begin{lemma}
For any pair of vertices $(u,v)$, $d(u,v)\geq \min(l_{u},l_{v})$
\end{lemma}
\begin{proof}
\item
Case 1: If vertex $u$ was visited by the algorithm before vertex $v$, then $v$ was a candidate for the closest unvisited vertex from $u$. Therefore, edge $(u,v)$ is no shorter than the edge leaving vertex $u$. Therefore, $d(u,v)\geq l_{u}$
\item
Case 2: If vertex $u$ was visited by the algorithm after vertex $v$, then $u$ was a candidate for the closest unvisited vertex from $v$. Therefore, edge $(u,v)$ is no shorter than the edge leaving vertex $v$. Therefore, $d(u,v)\geq l_{v}$
\item Either case 1 or case 2 must be true. Therefore, $d(u,v)\geq \min(l_{u},l_{v})$
\end{proof}
\begin{lemma}
For any vertex $u$, $2l_{u}\leq OPT$
\end{lemma}
\begin{proof}
Consider breaking the optimal tour into two disjoint paths P and Q, where P starts from $u$ and ends at $v$, and Q starts from $v$ and ends at $u$. Therefore, 
\[OPT = cost(P) + cost(Q)\]
Because of triangular equality, $d(u,v)\leq cost(P)$ and $d(u,v)\leq cost(Q)$. Therefore, 
\[2d(u,v)\leq OPT\]
Therefore, 
\[2l_{u}\leq OPT\]

\end{proof}
\end{proof}

\subsection{Minimum Spanning Tree}
\subsection{2-opt Algorithm}
\subsection{1.5 Approximation Algorithm}

\section{Implementations and Experiments}

\section{Conclusions}

\section{Bibliography}
\bibliographystyle{plain}
\nocite{*}
\bibliography{biblio}
%%% End document
\end{document}